---
title: 'Comparisons'
---

When choosing which LLM to use, it's often very useful to simply get a "vibe check",
and see which LLMs seem to respond best to the kinds of questions you'd like to ask.

Trying out LLMs one after the other can be tedious. We've therefore made it very easy to
compare LLM outputs to the same question side-by-side, both via our browser-based
[chat interface](), and the [X]() class in our Python SDK.

Check out [this video]() for a run-through of the chat interface.

An equivalent experience can be spun up in Python very quickly, as follows:

CODE