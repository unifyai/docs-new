---
title: 'Get Completions'
api: 'POST /v0/chat/completions'
---
OpenAI compatible /chat/completions endpoint for LLM inference.

#### Authorizations

<ParamField header="Authorization" type="string" required="true">
  Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.
</ParamField>

#### Body

<ParamField body="model" type="string" required="true">
None
</ParamField>

<ParamField body="messages" type="[object]" required="true">
None
</ParamField>

<ParamField body="temperature" type="number" >
None
</ParamField>

<ParamField body="stream" type="boolean" >
None
</ParamField>

<ParamField body="max_tokens" type="integer | null" >
None
</ParamField>

<ParamField body="frequency_penalty" type="number | null" >
None
</ParamField>

<ParamField body="logit_bias" type="object | null" >
None
</ParamField>

<ParamField body="logprobs" type="boolean | null" >
None
</ParamField>

<ParamField body="top_logprobs" type="integer | null" >
None
</ParamField>

<ParamField body="n" type="integer | null" >
None
</ParamField>

<ParamField body="presence_penalty" type="number | null" >
None
</ParamField>

<ParamField body="response_format" type="object | null" >
None
</ParamField>

<ParamField body="seed" type="integer | null" >
None
</ParamField>

<ParamField body="stop" type="string | array | null" >
None
</ParamField>

<ParamField body="top_p" type="number | null" >
None
</ParamField>

<ParamField body="tools" type="array | null" >
None
</ParamField>

<ParamField body="tool_choice" type="any | null" >
None
</ParamField>

<ParamField body="user" type="string | null" >
None
</ParamField>

<ParamField body="signature" type="string | null" >
None
</ParamField>

<ParamField body="use_custom_keys" type="boolean | null" >
None
</ParamField>

<RequestExample>

```bash cURL
curl --request POST \
  --url 'https://api.unify.ai/v0/chat/completions' \
  --header 'Authorization: Bearer <UNIFY_KEY>' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "gpt-4o-mini@openai",
    "messages": [
        {
            "content": "Tell me a joke",
            "role": "user"
        }
    ],
    "temperature": 0.9,
    "stream": false,
    "max_tokens": 1024
}'
```

```python Python
import requests

url = "https://api.unify.ai/v0/chat/completions"

headers = {"Authorization": "Bearer <token>"}

json_input = {"model": "gpt-4o-mini@openai", "messages": [{"content": "Tell me a joke", "role": "user"}], "temperature": 0.9, "stream": False, "max_tokens": 1024}

response = requests.request("POST", url, json=json_input, headers=headers)

print(response.text)
```

</RequestExample>
<ResponseExample>

```json 200
{
    "model": "string",
    "created": "integer | null",
    "id": "string | null",
    "object": "string",
    "usage": "object",
    "choices": "[object]"
}
```

```json 422
{
    "detail": [
        {
            "loc": [
                "string"
            ],
            "msg": "string",
            "type": "string"
        }
    ]
}
```

</ResponseExample>
