---
title: 'Datasets'
---

Prompt datasets are simply a collection of
[Prompts](https://github.com/unifyai/unify/blob/26247d88da2d46dea62fe0a665934f7f98523c92/unify/types.py#L23)
which are stored in your account,
with extra fields optionally also included in the dataset,
such as reference answers etc.

The primary use case for these datasets is to group prompts into various helpful test
cases and test sets, which can then form part of an evaluation pipeline.

Firstly, we cover topics focused on local development: [Creation](#creation),
[Indexing and Iterating](#indexing-and-iterating), [Combining](#combining)
and [Trimming](#trimming). This covers everything you need to know for purely local development,
which can be great for initial experimentation.

However, if
you need these experiments to be preserved across sessions,
you need to work with other team members, or you need to handle large volumes of data,
then you'll need to connect and synchronize your datasets with your unify account.
This is what's covered in the final sections: [Uploading](#uploading),
[Downloading](#downloading) and [Synchronizing](#synchronizing).

## Composition

Each dataset entry is a pydantic
[Datum](https://github.com/unifyai/unify/blob/b7743c6b204633c7eb77a65a1107c2031aec18a9/unify/types.py#L123)
instance, which contains a `prompt` field of type `Prompt`, with the pydantic
argument `extra=Extra.allow`, enabling *extra arbitrary fields*.

A `Datum` instance can be initialized as follows. If a single string is passed,
then this is interpreted as the user message
(also the case with `Prompt` initialization):

```python
import unify
datum = unify.Datum("This is a user message.")
```
```
Datum(
    prompt=Prompt(
        messages=[{'content': 'This is a user message.', 'role': 'user'}]
    )
)
```

A prompt can also be passed explicitly, with *optional extra fields* as well:

```python
import unify
datum = unify.Datum(
    prompt=unify.Prompt(
        "This is a user message."
    ),
    ref_answer="This is an answer."
)
```
```
Datum(
    prompt=Prompt(
        messages=[{'content': 'This is a user message.', 'role': 'user'}]
    ),
    ref_answer='This is an answer.'
)
```

## Creation

A dataset is just a collection of `Datum` instances.
Creating a local dataset is very simple:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
```

When a list of strings is passed, these strings are also interpreted as *user messages*,
but as explained above, the underlying dataset will contains `Datum` instances,
which themselves contain `Prompt` instances:

```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        )
    ]
)
```

Prompts can also be passed directly into the constructor:

```python
import unify
dataset = unify.Dataset([
    unify.Prompt(
        messages=[{'content': 'First user message.', 'role': 'user'}],
        temperature=0.2
    ),
    unify.Prompt(
        messages=[{'content': 'Second user message.', 'role': 'user'}],
        temperature=0.4
    ),
    unify.Prompt(
        messages=[{'content': 'Third user message.', 'role': 'user'}],
        temperature=0.6
    ),
])
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}],
                temperature=0.2
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}],
                temperature=0.4
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}],
                temperature=0.6
            )
        )
    ]
)
```

Similarly, Datum instances can also be passed into the constructor, which can
optionally have extra arbitrary fields (due to `extra=Extra.allow`),
such as `ref_answer`:

```python
import unify
dataset = unify.Dataset([
    unify.Datum(
        prompt=unify.Prompt(
            messages=[{'content': 'First user message.', 'role': 'user'}],
            temperature=0.2
        ),
        ref_answer="First answer."
    ),
    unify.Datum(
        prompt=unify.Prompt(
            messages=[{'content': 'First user message.', 'role': 'user'}],
            temperature=0.2
        ),
        ref_answer="Second answer."
    ),
    unify.Datum(
        prompt=unify.Prompt(
            messages=[{'content': 'First user message.', 'role': 'user'}],
            temperature=0.2
        ),
        ref_answer="Third answer."
    ),
])
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}],
                temperature=0.2
            ),
            ref_answer='First answer.'
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}],
                temperature=0.2
            ),
            ref_answer='Second answer.'
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}],
                temperature=0.2
            ),
            ref_answer='Third answer.'
        )
    ]
)
```

`str`, `Prompt` and `Datum` instances can also be passed individually, and these will be
interpreted as single-item datasets:

```python
import unify
dataset = unify.Dataset("First user message.")
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        )
    ]
)
```

## Indexing and Iterating

Datasets can be iterated over as follows:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
for entry in dataset:
    assert isinstance(entry, unify.Datum)
    print(entry)
```

Similarly, they can be indexed:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
assert isinstance(dataset[1], unify.Datum)
print(dataset[1])
```

They can also be sliced:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message.",
    "Fourth user message."
])
print(dataset[1:-1])
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        )
    ]
)
```

It's also possible to check whether one item or dataset is a subset of another dataset:

```python
import unify
dataset1 = unify.Dataset(["a", "b", "c"])
dataset2 = unify.Dataset(["a", "b"])
assert dataset2 in dataset1
assert "a" in dataset1
assert unify.Prompt("b") in dataset1
assert ["b", "c"] in dataset1
assert "d" not in dataset1
dataset3 = unify.Dataset(["c", "d"])
assert dataset3 not in dataset1
```

## Combining

Datasets can be added together to create combined datasets easily:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
])
dataset2 = unify.Dataset([
    "Third user message.",
    "Fourth user message.",
])
print(dataset1 + dataset2)
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Fourth user message.', 'role': 'user'}]
            )
        )
    ]
)
```

Duplicates will also be handled, such that entries in both datasets are not repeated:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
])
dataset2 = unify.Dataset([
    "Second user message.",
    "Third user message.",
])
print(dataset1 + dataset2)
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        )
    ]
)
```

In the above example, a new `Dataset` instance is created. However, datasets can also be
updated inplace via addition, as follows:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
])
dataset2 = unify.Dataset([
    "Third user message.",
    "Fourth user message.",
])
dataset1 += dataset2
```

Addition also works with *all types which can be passed into the dataset constructor*.
In such cases, the item will be automatically passed to the constructor to create a
`Dataset`:

```python
import unify
dataset = unify.Dataset(["First user message."])
dataset += "Second user message."
dataset += unify.Prompt(messages=[{'content': 'Third user message.', 'role': 'user'}])
dataset += ["Fourth user message.", "Fifth user message."]
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Fourth user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Fifth user message.', 'role': 'user'}]
            )
        )
    ]
)
```

The ordering of the operation also does not matter, by virtue of `__radd__` and
`__rsub__` implemented for the `Dataset` class:

```python
import unify
"User message" + unify.Dataset("Another user message.")
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'User message', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[
                    {'content': 'Another user message.', 'role': 'user'}
                ]
            )
        )
    ]
)
```

The same is true for `Prompt` and `Datum` instances, which can simply be summed
to create a `Dataset`.

```python
import unify
dataset = "First user message." \
           + unify.Prompt("Second user message.") \
           + unify.Datum("Third user message")
print(dataset)
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message', 'role': 'user'}]
            )
        )
    ]
)
```

## Trimming

Datasets can also be subtracted from one another easily, as follows:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message.",
    "Fourth user message.",
])
dataset2 = unify.Dataset([
    "Second user message.",
    "Fourth user message.",
])
print(dataset1 - dataset2)
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        )
    ]
)
```

As with addition, in the above examples a new `Dataset` instance is created.
However, datasets can also be updated inplace via subtraction, as follows:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message.",
    "Fourth user message.",
])
dataset2 = unify.Dataset([
    "Second user message.",
    "Fourth user message.",
])
dataset1 -= dataset2
```

All of the points made in the previous section about addition also apply for
subtraction. For example, individual entries can be removed from a `Dataset` by value,
like so:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
dataset -= "First user message"
dataset = dataset - unify.Prompt("Second user message.")
print(dataset)
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        )
    ]
)
```

This section is less verbose than the previous section in order to avoid
repetition, but all points made apply equally in this case as well, and you're
encouraged to test things out accordingly!

## Uploading

You can see your listed datasets on the [Datasets](https://console.unify.ai/datasets)
page of your account.

<p align="left">
    <img src="/images/datasets_page_empty.png" alt="Datasets Empty" />
</p>

By default, there is a single dataset added to all new accounts: "Open Hermes".
This is...

In order to synchronize your local dataset with an upstream dataset in the platform,
your dataset **needs to have a name**.

If this was not set in the constructor, then it can be set as follows:

```python
dataset.set_name("my_dataset")
```

Provided your dataset has a name, it can then be uploaded to your account like so:

```python
dataset.upload()
```

This will not overwrite any dataset entries which are contained in the upstream dataset,
it will only add any missing entries.
If you want to fully overwrite any existing upstream dataset called "my_dataset",
then pass `overwrite=True`:

```python
dataset.upload(overwrite=True)
```

Once your dataset has been uploaded, you'll be able to see it in the console like so:

<p align="left">
    <img src="/images/datasets_page_w_upload.png" alt="Datasets with Upload" />
</p>

The dataset can be renamed, deleted, and viewed from the console.
Clicking `View Dataset` will present the following view of the dataset:

IMAGE

## Downloading

You can directly download a dataset from your account as follows:

```python
import unify
dataset = unify.Dataset.from_upstream("my_dataset")
```
```
Dataset(
    [
        Datum(
            prompt=Prompt(
                messages=[{'content': 'First user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Second user message.', 'role': 'user'}]
            )
        ),
        Datum(
            prompt=Prompt(
                messages=[{'content': 'Third user message.', 'role': 'user'}]
            )
        )
    ]
)
```

If you have a local copy of a dataset, and someone else has pushed changes to the
upstream version in a shared team account, then you can download those changes into your
own local dataset version, *without overwriting your own local changes*:

```python
dataset.download()
```

If you want to overwrite your local changes, then pass `overwrite=True`:

```python
dataset.download(overwrite=True)
```

This is equivalent to creating a new dataset instance
`dataset = unify.Dataset.from_upstream("my_dataset")`, but the `id` of the
`Dataset` instance will be preserved when calling `dataset.download(overwrite=True)`,
as the update will happen in-place.

## Synchronizing

If you want to synchronize your dataset with the upstream dataset in **both
directions**, then you can call `.sync()` as follows:

```python
dataset.sync()
```

This is implemented as a call to `.download()` (add any missing upstream entries to the
local database) followed by a call to `.upload()` (add any missing local entries to the
upstream database). Therefore, `.sync()` will bring both datasets into alignment, such
that they both contain the *superset* of entries from both the local and upstream
versions.

By default, auto-synchronization is turned off, but if you want your local dataset to
remain synchronized with the upstream dataset **at all times**,
then you can set `auto_sync=True` in the constructor, as follows:

```python
import unify
dataset = unify.Dataset(
    [
        "First user message.",
        "Second user message.",
        "Third user message."
    ],
    auto_sync=True
)
```

Similarly, you can set this via the setter method.
This is useful if you've downloaded your dataset for example:

```python
dataset = unify.Dataset.from_upstream("my_dataset")
dataset.set_auto_sync(True)
assert dataset.auto_sync
```

When `dataset.auto_sync is True`, this will call `.sync()` **every time** any method is
called on the local `Dataset` instance (even if that method does not change the
`Dataset` contents). This does mean that upstream changes will **not** be
synchronized until a method is called on the local `Dataset`, but new local changes will
**always** be fully synchronized with upstream. It's worth keeping this asymmetry in
mind, understanding that local changes do trigger the sync, but upstream changes do not
trigger the sync. If you need track upstream changes, then you'll need to occasionally
call `.sync()` or `.download()` explicitly on your local dataset.

Setting `dataset.auto_sync` to `True` will configure bi-directional synchronization, but
sometimes you might only care about synchronization in one direction. You might only
want to retrieve upstream changes but not upload anything, or you might only want to add
to the upstream dataset without downloading anything. The `auto_sync` parameter can also
be set as `"download_only"` or `"upload_only"` (or `"both"` which is the same as
`True`), for example:

```python
dataset = unify.Dataset.from_upstream("my_dataset")
dataset.set_auto_sync("upload_only")
```

```python
import unify
dataset = unify.Dataset(
    [
        "First user message.",
        "Second user message.",
        "Third user message."
    ],
    auto_sync="download_only"
)
```

These settings will only trigger synchronizations in *one direction*,
again triggered every time a method is called on the local `Dataset`.