---
title: 'Datasets'
---

Datasets are basically a collection of **any data type**, which can then be easily
stored in your account and shared with your team.

One obvious use case for these datasets is to group prompts into various helpful test
cases and test sets, which can then form part of an evaluation pipeline. We will unpack
this use case further in the subsequent Evaluations section.

Firstly, lets understand what a Dataset actually is! In the following sections,
we explain: [Creation](#creation), [Indexing and Iterating](#indexing-and-iterating),
[Combining](#combining), [Trimming](#trimming) and [One-Liners](#one-liners) on
datasets. This covers everything you need to know to get started with some initial
experimentation using datasets locally.

However, if you need these experiments to be preserved across sessions,
you need to work with other team members, or you need to handle large volumes of data,
then you'll need to connect and synchronize your datasets with your unify account.
This is what's covered in the final sections: [Uploading](#uploading),
[Downloading](#downloading) and [Synchronizing](#synchronizing).

## Creation

A dataset is simply a collection of data, where each entry can be *any serializable
Python type*. Creating a local dataset is very simple:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
```
```
Dataset(['First user message.', 'Second user message.', 'Third user message.'])
```

You can also pass more complex types, such as the full
[Prompt](https://docs.unify.ai/python/types/chat/prompt/Prompt)
instances, which can optionally include tool calls, temperature, formatted outputs etc:


```python
import unify
dataset = unify.Dataset([unify.Prompt("This is a message.")])
```
```
Dataset(
    [
        Prompt(
            messages=[{'content': 'This is a message.', 'role': 'user'}],
            frequency_penalty=None,
            logit_bias=None,
            logprobs=None,
            top_logprobs=None,
            max_completion_tokens=None,
            n=None,
            presence_penalty=None,
            response_format=None,
            seed=None,
            stop=None,
            temperature=None,
            top_p=None,
            tools=None,
            tool_choice=None,
            parallel_tool_calls=None,
            extra_headers=None,
            extra_query=None,
            extra_body=None
        )
    ]
)
```

Again, this is better visualized after setting `unify.set_repr_mode("concise")`.
We will assume `"concise"` mode for the rest of the examples on this page:

```
Dataset([Prompt(messages=[{'content': 'This is a message.', 'role': 'user'}])])
```

## Indexing and Iterating

Datasets can be iterated over as follows:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
for entry in dataset:
    assert isinstance(entry, str)
```

Similarly, they can be indexed:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
assert isinstance(dataset[1], str)
```

They can also be sliced:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message.",
    "Fourth user message."
])
print(dataset[1:-1])
```
```
Dataset(['Second user message.', 'Third user message.'])
```

It's also possible to check whether one item or dataset is a subset of another dataset:

```python
import unify
dataset1 = unify.Dataset(["a", "b", "c"])
dataset2 = unify.Dataset(["a", "b"])
assert dataset2 in dataset1
assert "a" in dataset1
assert "b" in dataset1
assert ["b", "c"] in dataset1
assert "d" not in dataset1
dataset3 = unify.Dataset(["c", "d"])
assert dataset3 not in dataset1
```

## Combining

Datasets can be added together to create combined datasets easily:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
])
dataset2 = unify.Dataset([
    "Third user message.",
    "Fourth user message.",
])
print(dataset1 + dataset2)
```
```
Dataset(
    [
        'First user message.',
        'Second user message.',
        'Third user message.',
        'Fourth user message.'
    ]
)
```

Duplicates will also be handled, such that entries in both datasets are not repeated:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
])
dataset2 = unify.Dataset([
    "Second user message.",
    "Third user message.",
])
print(dataset1 + dataset2)
```
```
Dataset(['First user message.', 'Second user message.', 'Third user message.'])
```

In the above example, a new `Dataset` instance is created. However, datasets can also be
updated inplace via addition, as follows:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
])
dataset2 = unify.Dataset([
    "Third user message.",
    "Fourth user message.",
])
dataset1 += dataset2
```

Addition also works with *all types which can be individually stored in a dataset*:

```python
import unify
dataset = unify.Dataset(["First user message."])
dataset += "Second user message."
dataset += unify.Prompt(messages=[{'content': 'Third user message.', 'role': 'user'}])
dataset += ["Fourth user message.", "Fifth user message."]
```
```
Dataset(
    [
        'First user message.',
        'Second user message.',
        Prompt(messages=[{'content': 'Third user message.', 'role': 'user'}]),
        'Fourth user message.',
        'Fifth user message.'
    ]
)
```

The ordering of the operation also does not matter, by virtue of `__radd__` and
`__rsub__` implemented for the `Dataset` class:

```python
import unify
"User message" + unify.Dataset("Another user message.")
```
```
Dataset(['User message', 'Another user message.'])
```

## Trimming

Datasets can also be subtracted from one another easily, as follows:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message.",
    "Fourth user message.",
])
dataset2 = unify.Dataset([
    "Second user message.",
    "Fourth user message.",
])
print(dataset1 - dataset2)
```
```
Dataset(['First user message.', 'Third user message.'])
```

As with addition, in the above examples a new `Dataset` instance is created.
However, datasets can also be updated inplace via subtraction, as follows:

```python
import unify
dataset1 = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message.",
    "Fourth user message.",
])
dataset2 = unify.Dataset([
    "Second user message.",
    "Fourth user message.",
])
dataset1 -= dataset2
```

All of the points made in the previous section about addition also apply for
subtraction. For example, individual entries can be removed from a `Dataset` by value,
like so:

```python
import unify
dataset = unify.Dataset([
    "First user message.",
    "Second user message.",
    "Third user message."
])
dataset -= "First user message."
dataset = dataset - "Second user message."
print(dataset)
```
```
Dataset(['Third user message.'])
```

This section is less verbose than the previous section in order to avoid
repetition, but all points made apply equally in this case as well, and you're
encouraged to test things out accordingly!

## One-Liners

All `Dataset` methods which perform in-place updates also return `self`.
This makes it possible to chain in-place methods together:

```python
import unify
("1st msg" + unify.Prompt("2nd msg.")).set_name("my_dataset").upload()
```

If the return is not caught from any of these inplace methods,
then this makes no difference to the behaviour:

```python
dataset.set_name("some_name")
```

## Uploading

You can see your listed datasets on the [Datasets](https://console.unify.ai/datasets)
page of your account.

<p align="left">
    <img src="/images/datasets_page_empty.png" alt="Datasets Empty" />
</p>

By default, there is a single dataset added to all new accounts: "Open Hermes".
This is a random sample of 1000 prompts from the
[Open Hermes](https://huggingface.co/datasets/teknium/OpenHermes-2.5) dataset.


In order to synchronize your local dataset with an upstream dataset in the platform,
your dataset **needs to have a name**.

If this was not set in the constructor, then it can be set as follows:

```python
dataset.set_name("my_dataset")
```

Provided your dataset has a name, it can then be uploaded to your account like so:

```python
dataset.upload()
```

This will not overwrite any dataset entries which are contained in the upstream dataset,
it will only add any missing entries.
If you want to fully overwrite any existing upstream dataset called "my_dataset",
then pass `overwrite=True`:

```python
dataset.upload(overwrite=True)
```

Once your dataset has been uploaded, you'll be able to see it in the console like so:

<p align="left">
    <img src="/images/datasets_page_w_upload.png" alt="Datasets with Upload" />
</p>

The dataset can be renamed, deleted, and viewed from the console.
Clicking `View Dataset` will present the following view of the dataset:

IMAGE

Dataset names can also be used to specify the directory structure which is observed
inside your user account. For example, the following dataset will appear in the
`maths_quiz` folder and `john_smith` sub-folder, with the dataset name `answers`:

```python
import unify
unify.Dataset(["a", "b", "c"]).set_name("maths_quiz/john_smith/answers").upload()
```

This makes it much easier to organize datasets in a hierarchical manner, and it also
makes things easier to manage in the console, where datasets can be moved and
re-organized freely:

IMAGE

## Downloading

You can directly download a dataset from your account as follows:

```python
import unify
dataset = unify.Dataset.from_upstream("my_dataset")
```
```
Dataset(['First user message.', 'Second user message.', 'Third user message.'])
```

If you have a local copy of a dataset, and someone else has pushed changes to the
upstream version in a shared team account, then you can download those changes into your
own local dataset version, *without overwriting your own local changes*:

```python
dataset.download()
```

If you want to overwrite your local changes, then pass `overwrite=True`:

```python
dataset.download(overwrite=True)
```

This is equivalent to creating a new dataset instance
`dataset = unify.Dataset.from_upstream("my_dataset")`, but the `id` of the
`Dataset` instance will be preserved when calling `dataset.download(overwrite=True)`,
as the update will happen in-place.

## Synchronizing

If you want to synchronize your dataset with the upstream dataset in **both
directions**, then you can call `.sync()` as follows:

```python
dataset.sync()
```

This is implemented as a call to `.download()` (add any missing upstream entries to the
local database) followed by a call to `.upload()` (add any missing local entries to the
upstream database). Therefore, `.sync()` will bring both datasets into alignment, such
that they both contain the *superset* of entries from both the local and upstream
versions.