---
title: 'On-Prem'
---

## Sign up to the platform

The first step is to create an account via our [console](https://console.unify.ai/).
This is just a one time requirement, in order to create your unique user ID and API key.
The entire console is replicated in the on-prem offering, all deployed locally.

## Get access to the docker images

All images for on-prem deployment are available on Docker Hub.
These are *private images*, with access granted to users on our
[Enterprise Plan](https://unify.ai/pricing).
If you would like to get access for on-prem deployment,
then [get in touch](https://calendly.com/unify-chat/general) with us!

## Pull the images

In order to set up on-prem, you need to pull the following 3 images:
- **unifyorg/orchestra-on-prem:latest**: The backend app
- **unifyorg/dataset-evaluation-on-prem:latest**: The dataset evaluation service
- **unifyorg/unify-interfaces-on-prem:latest**: The console app

Given that these images are private,
you first need to [log into docker](https://docs.docker.com/reference/cli/docker/login/)
in your terminal before pulling the images.
We will give your docker account read-only access to the images,
as part of the [enterprise](https://unify.ai/pricing) onboarding process.

## Local folder structure

We will also share a folder with you called `on-prem`, which contains six files,
as explained below.

Firstly, the following three files store environment variables for the three
different applications:

- `.env-console` contains the necessary environment variables to set up the console app
- `.env-db` contains the necessary environment variables to set up the database app
- `.env-orchestra` contains the necessary environment variables to set up the backend app

There are also two `.json` files, as explained below:

- `sessionInfo.json` contains the session information for the console app, it‚Äôs mainly used for
displaying data on your profile page. The file should contain the following fields when
we share the folder with you:
    - `name`: first name
    - `email`: email id
    - `image`: a link to the profile image

- `userInfo.json` contains more information about the user currently using the app.
This is something we need to do so to bypass the login process. The file should contain
the following fields when we share the folder with you:
    - `id`: user id
    - `name`: first name
    - `lastName`: last name
    - `image`: a link to the profile image
    - `email`: the email id
    - `createdAt`: the date when the account was created
    - `apiKey`: the details about your api key
    - `UserDetails`: your organization and jobTitle (Optional)

Finally, there is also a Docker Compose file, which stores the configuration for
orchestrating everything via Docker Compose, which spins up the containers:

- `docker-compose.yaml`: contains the configuration for starting the Docker Compose service

## Setting up

In order to set up, you would need to populate the `.env_orchestra` file with the
credentials of the providers you would like to use:

- For providers like OpenAI, Anthropic, etc. (which require a single API key),
you would need to add your key corresponding to the `ORCHESTRA_OPENAI_KEY` variable and
so on.
- For using AWS Bedrock, you would need to add,
    - `AWS_SECRET_KEY_ID`
    - `AWS_SECRET_ACCESS_KEY`
    - `AWS_REGION` (the location can also be instead passed as the `region` field in
  `/chat/completions`)
- For using VertexAI, you would need to add,
    - `GOOGLE_APPLICATION_CREDENTIALS`
    - `ORCHESTRA_VERTEXAI_PROJECT`
    - `ORCHESTRA_VERTEXAI_LOCATION` (again, the location can also be instead passed as
  the `region` field in `/chat/completions`)

Along with the above, you would also need to uncomment a line in the
`docker-compose.yaml` that mounts the service account `.json` onto the container.
For e.g. if `application_default_credentials.json` is the name of the file, then
`GOOGLE_APPLICATION_CREDENTIALS` would be set as
`/app/src/application_default_credentials.json`.

Once you‚Äôve set the environment variables, you can now spin up the containers for the
images by running `docker compose up` in the same folder as the `docker-compose.yaml`
file. There's a total of 5 containers that should be running:
- `console`
- `orchestra`
- `dataset_evaluation`
- `db`
- `redis`

The containers should start running after that, you should wait until you see the log
entry of on-prem-orchestra saying "Uvicorn running on `http://0.0.0.0:8000`"
(as `orchestra` takes a few seconds to be up and running). After that is displayed,
you‚Äôre set to start using the console!

## Usage

The console should be usable at `http://localhost:3000`, you should be able to access
features like uploading datasets, running evaluations, adding custom api keys,
adding custom endpoints etc. You can also use all the endpoints in the
[API Reference](https://docs.unify.ai/api-reference) by making calls to
`http://localhost:8000` instead of `https://api.unify.ai`

## Python Client

In order to use the [python client](https://docs.unify.ai/basics/quickstart) with the
on-prem deployment, you need to set the `UNIFY_BASE_URL` environment variable as
the address to the orchestra service. For e.g. if you're using the python client in the
same host as the orchestra service, then you should set the `UNIFY_BASE_URL` to
`http://localhost:8000`.

## Updates

The Docker images will continue to be updated regularly as the platform continues to
evolve, with new features released on a weekly basis.
In order to update your local environment based on the latest versions,
you would need to:
- Pull the latest images: [same as above](#pull-the-images)
- Update the service to use the latest image: `docker compose up -d --no-deps --build <service_name>`

> **\<service_name\>** can be one of `console`, `orchestra` or `dataset_evaluation`.
> The goal here is to make sure that your data remains intact,
> so we would advice against deleting the `db` service.

## Support

Our [Enterprise Plan](https://unify.ai/pricing) includes full
**hands-on support and services**, so of course feel free to ping us any time,
and we'll dive in and make sure everything is running smoothly on your end! üßë‚Äçüíª