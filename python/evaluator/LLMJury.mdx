---
title: 'LLMJury'
---

```python
class LLMJury
```



## properties

---

### class\_config

```python
def class_config(self) -> Dict[float, str]:
```



---

### name

```python
def name(self) -> Optional[str]:
```



---

### scorer

```python
def scorer(self) -> Type[Score]:
```



## setters

---

### set\_name

```python
def set_name(self, value: str):
```



## methods

---

### class\_config

```python
def class_config(self) -> Dict[float, str]:
```



---

### evaluate

```python
def evaluate(
            self,
            prompt: Union[str, Prompt],
            response: Union[ChatCompletion, str],
            agent: Union[str, _Client, Agent],
            **kwargs
    ) -> Union[Evaluation, EvaluationSet]:
```

Evaluate the given response for this input prompt, with optional extra data.

**Arguments**:

- `prompt` - The user message or the full input prompt being responded to.
- `response` - The response which is being evaluated, either as just the most
- `agent` - The agent that made the response, which is being evaluated.
- `kwargs` - Extra information relevant to the prompt, as is stored in the Datum.



**Returns**:

An Evaluation instance, containing the prompt, response, agent, score and
optional extra data used during the evaluation.

---

### name

```python
def name(self) -> Optional[str]:
```



---

### scorer

```python
def scorer(self) -> Type[Score]:
```



## dunder_methods

---

### \_\_init\_\_

```python
def __init__(
            self,
            judges: List[LLMJudge],
            name: Optional[str] = None,
            include_rationale: bool = False,
    ):
```

Creates an LLM as a Judge Evaluator.

**Arguments**:

- `judges` - The client to use as the LLM Judge.
- `name` - The name to give to this LLM Judge evaluator, optional.
- `include_rationale` - Whether to include the LLM's rationale as part of