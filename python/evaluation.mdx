---
title: 'evaluation'
---

<a id="evaluation.Evaluation"></a>

## Evaluation

```python
class Evaluation()
```

<a id="evaluation.Evaluation.__init__"></a>

---

### \_\_init\_\_

```python
def __init__(agent: Union[Agent, str],
             dataset: Union[Dataset, str],
             evaluator: Union[Evaluator, str],
             auto_sync: bool = False,
             api_key: Optional[str] = None)
```

Initialize a local evaluation for a dataset of LLM queries.

**Arguments**:

- `agent` - The agent that is being evaluated, either a local LLM agent or a
  string for an endpoint available in the platform.
  
- `dataset` - The dataset that the evaluation has been performed on.
  
- `evaluator` - The evaluator that has been judging the quality of responses.
  
- `auto_sync` - Whether to automatically keep this dataset fully synchronized
  with the upstream variant at all times.
  
- `api_key` - API key for accessing the Unify API. If None, it attempts to
  retrieve the API key from the environment variable UNIFY_KEY. Defaults to
  None.
  

**Raises**:

- `UnifyError` - If the API key is missing.

<a id="evaluation.Evaluation.from_upstream"></a>

---

### from\_upstream

```python
@staticmethod
def from_upstream(agent: str,
                  dataset: str,
                  evaluator: str,
                  auto_sync: bool = False,
                  api_key: Optional[str] = None)
```

Initialize a local evaluation for a dataset of LLM queries.

**Arguments**:

- `agent` - The agent that is being evaluated, either a local LLM agent or a
  string for an endpoint available in the platform.
  
- `dataset` - The dataset that the evaluation has been performed on.
  
- `evaluator` - The evaluator that has been judging the quality of responses.
  
- `auto_sync` - Whether to automatically keep this dataset fully synchronized
  with the upstream variant at all times.
  
- `api_key` - API key for accessing the Unify API. If None, it attempts to
  retrieve the API key from the environment variable UNIFY_KEY. Defaults to
  None.
  

**Raises**:

- `UnifyError` - If the API key is missing.

<a id="evaluation.Evaluation.from_file"></a>

---

### from\_file

```python
@staticmethod
def from_file(filepath: str,
              agent: Union[Agent, str],
              evaluator: Union[Evaluator, str],
              auto_sync: bool = False,
              api_key: Optional[str] = None)
```

Loads the evaluation from a local .jsonl filepath.

**Arguments**:

- `filepath` - Filepath (.jsonl) to load the dataset from.
  
- `agent` - The agent that is being evaluated, either a local LLM agent or a
  string for an endpoint available in the platform.
  
- `evaluator` - The evaluator that has been judging the quality of responses.
  
- `auto_sync` - Whether to automatically keep this dataset fully synchronized
  with the upstream variant at all times.
  
- `api_key` - API key for accessing the Unify API. If None, it attempts to
  retrieve the API key from the environment variable UNIFY_KEY. Defaults to
  None.

<a id="evaluation.Evaluation.upload"></a>

---

### upload

```python
def upload(overwrite=False)
```

Uploads all unique local data in the dataset evaluation to the user account
upstream. This function will not download any uniques from upstream.
Use `sync` to synchronize and superset the datasets in both directions.
Set `overwrite=True` to disregard any pre-existing upstream data.

**Arguments**:

- `overwrite` - Whether to overwrite the upstream dataset if it already exists

<a id="evaluation.Evaluation.download"></a>

---

### download

```python
def download(overwrite=False)
```

Downloads all unique upstream data from the user account to the local dataset.
This function will not upload any unique values stored locally.
Use `sync` to synchronize and superset the datasets in both directions.
Set `overwrite=True` to disregard any pre-existing data stored in this class.

**Arguments**:

- `overwrite` - Whether to overwrite the local data, if any already exists

<a id="evaluation.Evaluation.sync"></a>

---

### sync

```python
def sync()
```

Synchronize the dataset in both directions, downloading any values missing
locally, and uploading any values missing from upstream in the account.

<a id="evaluation.Evaluation.upstream_diff"></a>

---

### upstream\_diff

```python
def upstream_diff()
```

Prints the difference between the local dataset and the upstream dataset.

<a id="evaluation.Evaluation.save_to_file"></a>

---

### save\_to\_file

```python
def save_to_file(filepath: str)
```

Saves to dataset to a local .jsonl filepath.

**Arguments**:

- `filepath` - Filepath (.jsonl) to save the dataset to.

<a id="evaluation.Evaluation.add"></a>

---

### add

```python
def add(other: __class__)
```

Adds another dataset to this one, return a new Dataset instance, with this
new dataset receiving all unique queries from the other added dataset.

**Arguments**:

- `other` - The other dataset being added to this one.

<a id="evaluation.Evaluation.sub"></a>

---

### sub

```python
def sub(other: __class__)
```

Subtracts another dataset from this one, return a new Dataset instance, with
this new dataset losing all queries from the other subtracted dataset.

**Arguments**:

- `other` - The other dataset being added to this one.

<a id="evaluation.Evaluation.__iadd__"></a>

---

### \_\_iadd\_\_

```python
def __iadd__(other)
```

Adds another dataset to this one, with this dataset receiving all unique queries
from the other added dataset.

**Arguments**:

- `other` - The other dataset being added to this one.

<a id="evaluation.Evaluation.__isub__"></a>

---

### \_\_isub\_\_

```python
def __isub__(other)
```

Subtracts another dataset from this one, with this dataset losing all queries
from the other subtracted dataset.

**Arguments**:

- `other` - The other dataset being added to this one.

<a id="evaluator"></a>
