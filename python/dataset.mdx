---
title: 'dataset'
---

<a id="dataset.Dataset"></a>

## Dataset

```python
class Dataset(_Formatted)
```

<a id="dataset.Dataset.__init__"></a>

---

### \_\_init\_\_

```python
def __init__(data: Union[str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                              Prompt, Datum]]],
             *,
             name: str = None,
             auto_sync: Union[bool, str] = False,
             api_key: Optional[str] = None) -> None
```

Initialize a local dataset of LLM queries.

**Arguments**:

- `data` - The data for populating the dataset. This can either can a list of
  user messages, a list of full queries, or a list of dicts of queries
  alongside any extra fields. Individual items in any of the formats listed
  above will also be converted to lists and processed automatically.
  
- `name` - The name of the dataset.
  
- `auto_sync` - Whether to automatically keep this dataset fully synchronized
  with the upstream variant at all times. If `True` or "both" then the sync
  will be bi-directional, if "upload" then all local changes will be
  uploaded to the upstream account without any downloads, if "download"
  then all upstream changes will be downloaded locally without any uploads.
  If "upstream_mirrors_local" then the upstream dataset will be anchored to the
  local version at all times, and any other uploads outside the local dataset
  will be overwritten. If "local_mirrors_upstream" then the local version will be
  anchored to the upstream version at all times, and any local changes will be
  overwritten. If `False` or "neither" then no synchronization will be done
  automatically.
  
- `api_key` - API key for accessing the Unify API. If None, it attempts to
  retrieve the API key from the environment variable UNIFY_KEY. Defaults to
  None.
  

**Raises**:

- `UnifyError` - If the API key is missing.

<a id="dataset.Dataset.name"></a>

---

### name

```python
@property
def name() -> str
```

Name of the dataset.

<a id="dataset.Dataset.auto_sync"></a>

---

### auto\_sync

```python
@property
def auto_sync() -> Union[bool, str]
```

The auto-sync mode currently selected.
This dictates whether to automatically keep this dataset fully synchronized
with the upstream variant at all times. If `True` or "both" then the sync
will be bi-directional, if "upload" then all local changes will be
uploaded to the upstream account without any downloads, if "download"
then all upstream changes will be downloaded locally without any uploads.
If "upstream_mirrors_local" then the upstream dataset will be anchored to the
local version at all times, and any other uploads outside the local dataset
will be overwritten. If "local_mirrors_upstream" then the local version will be
anchored to the upstream version at all times, and any local changes will be
overwritten. If `False` or "neither" then no synchronization will be done
automatically.

<a id="dataset.Dataset.set_name"></a>

---

### set\_name

```python
def set_name(name: str) -> Dataset
```

Set the name of the dataset.

**Arguments**:

- `name` - The name to set the dataset to.
  

**Returns**:

  This dataset, useful for chaining methods.

<a id="dataset.Dataset.set_auto_sync"></a>

---

### set\_auto\_sync

```python
def set_auto_sync(auto_sync: Union[bool, str]) -> Dataset
```

Set the value of the auto-sync flag.

**Arguments**:

- `auto_sync` - Whether to automatically keep this dataset fully synchronized
  with the upstream variant at all times. If `True` or "both" then the sync
  will be bi-directional, if "upload" then all local changes will be
  uploaded to the upstream account without any downloads, if "download"
  then all upstream changes will be downloaded locally without any uploads.
  If "upstream_mirrors_local" then the upstream dataset will be anchored to the
  local version at all times, and any other uploads outside the local dataset
  will be overwritten. If "local_mirrors_upstream" then the local version will be
  anchored to the upstream version at all times, and any local changes will be
  overwritten. If `False` or "neither" then no synchronization will be done
  automatically.
  

**Returns**:

  This dataset, useful for chaining methods.

<a id="dataset.Dataset.from_upstream"></a>

---

### from\_upstream

```python
@staticmethod
def from_upstream(name: str,
                  auto_sync: Union[bool, str] = False,
                  api_key: Optional[str] = None) -> Dataset
```

Initialize a local dataset of LLM queries, from the upstream dataset.

**Arguments**:

- `name` - The name of the dataset.
  
- `auto_sync` - Whether to automatically keep this dataset fully synchronized
  with the upstream variant at all times.
  
- `api_key` - API key for accessing the Unify API. If None, it attempts to
  retrieve the API key from the environment variable UNIFY_KEY. Defaults to
  None.
  

**Returns**:

  The dataset, with contents downloaded from upstream.
  

**Raises**:

- `UnifyError` - If the API key is missing.

<a id="dataset.Dataset.upload"></a>

---

### upload

```python
def upload(overwrite: bool = False) -> Dataset
```

Uploads all unique local data in the dataset to the user account upstream.
This function will not download any uniques from upstream.
Use `sync` to synchronize and superset the datasets in both directions.
Set `overwrite=True` to disregard any pre-existing upstream data.

**Arguments**:

- `overwrite` - Whether to overwrite the upstream dataset if it already exists.
  

**Returns**:

  This dataset, useful for chaining methods.

<a id="dataset.Dataset.download"></a>

---

### download

```python
def download(overwrite: bool = False) -> Dataset
```

Downloads all unique upstream data from the user account to the local dataset.
This function will not upload any unique values stored locally.
Use `sync` to synchronize and superset the datasets in both directions.
Set `overwrite=True` to disregard any pre-existing data stored in this class.

**Arguments**:

- `overwrite` - Whether to overwrite the local data, if any already exists
  

**Returns**:

  This dataset after the in-place download, useful for chaining methods.

<a id="dataset.Dataset.sync"></a>

---

### sync

```python
def sync() -> Dataset
```

Synchronize the dataset in both directions, downloading any values missing
locally, and uploading any values missing from upstream in the account.

**Returns**:

  This dataset after the in-place sync, useful for chaining methods.

<a id="dataset.Dataset.upstream_diff"></a>

---

### upstream\_diff

```python
def upstream_diff() -> Dataset
```

Prints the difference between the local dataset and the upstream dataset.

**Returns**:

  This dataset after printing the diff, useful for chaining methods.

<a id="dataset.Dataset.add"></a>

---

### add

```python
def add(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Adds another dataset to this one, return a new Dataset instance, with this
new dataset receiving all unique queries from the other added dataset.

**Arguments**:

- `other` - The other dataset being added to this one.
  

**Returns**:

  The new dataset following the addition.

<a id="dataset.Dataset.sub"></a>

---

### sub

```python
def sub(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Subtracts another dataset from this one, return a new Dataset instance, with
this new dataset losing all queries from the other subtracted dataset.

**Arguments**:

- `other` - The other dataset being added to this one.
  

**Returns**:

  The new dataset following the subtraction.

<a id="dataset.Dataset.__iadd__"></a>

---

### \_\_iadd\_\_

```python
def __iadd__(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Adds another dataset to this one, with this dataset receiving all unique queries
from the other added dataset.

**Arguments**:

- `other` - The other dataset being added to this one.
  

**Returns**:

  This dataset following the in-place addition.

<a id="dataset.Dataset.__isub__"></a>

---

### \_\_isub\_\_

```python
def __isub__(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Subtracts another dataset from this one, with this dataset losing all queries
from the other subtracted dataset.

**Arguments**:

- `other` - The other dataset being added to this one.
  

**Returns**:

  This dataset following the in-place subtraction.

<a id="dataset.Dataset.__add__"></a>

---

### \_\_add\_\_

```python
def __add__(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Adds another dataset to this one via the + operator, return a new Dataset
instance, with this new dataset receiving all unique queries from the other
added dataset.

**Arguments**:

- `other` - The other dataset being added to this one.
  

**Returns**:

  The new dataset following the addition.

<a id="dataset.Dataset.__radd__"></a>

---

### \_\_radd\_\_

```python
def __radd__(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Adds another dataset to this one via the + operator, this is used if the
other item does not have a valid __add__ method for these two types. Return a
new Dataset instance, with this new dataset receiving all unique queries from
the other added dataset.

**Arguments**:

- `other` - The other dataset being added to this one.
  

**Returns**:

  The new dataset following the addition.

<a id="dataset.Dataset.__sub__"></a>

---

### \_\_sub\_\_

```python
def __sub__(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Subtracts another dataset from this one via the - operator, return a new Dataset
instance, with this new dataset losing all queries from the other subtracted
dataset.

**Arguments**:

- `other` - The other dataset being subtracted from this one.
  

**Returns**:

  The new dataset following the subtraction.

<a id="dataset.Dataset.__rsub__"></a>

---

### \_\_rsub\_\_

```python
def __rsub__(
    other: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                               Prompt, Datum]]]
) -> Dataset
```

Subtracts another dataset from this one via the - operator, this is used if the
other item does not have a valid __sub__ method for these two types. Return a
new Dataset instance, with this new dataset losing all queries from the other
subtracted dataset.

**Arguments**:

- `other` - The other dataset being subtracted from this one.
  

**Returns**:

  The new dataset following the subtraction.

<a id="dataset.Dataset.__iter__"></a>

---

### \_\_iter\_\_

```python
def __iter__() -> Datum
```

Iterates through the dataset, return one Datum instance at a time.

**Returns**:

  A Datum instance per iteration.

<a id="dataset.Dataset.__contains__"></a>

---

### \_\_contains\_\_

```python
def __contains__(
    item: Union[Dataset, str, Dict, Prompt, Datum, List[Union[str, Dict,
                                                              Prompt, Datum]]]
) -> bool
```

Determine whether the item is contained within the dataset. The item is cast to
a Dataset instance, and can therefore take on many different types. Only returns
True if *all* entries in the passed dataset are contained within this dataset.

**Arguments**:

- `item` - The item to cast to a Dataset before checking if it's a subset of this
  one.
  

**Returns**:

  Boolean, as to whether or not the passed Dataset is a subset of this one.

<a id="dataset.Dataset.__len__"></a>

---

### \_\_len\_\_

```python
def __len__() -> int
```

Returns the number of entries contained within the dataset.

**Returns**:

  The number of entries in the dataset.

<a id="dataset.Dataset.__getitem__"></a>

---

### \_\_getitem\_\_

```python
def __getitem__(item: Union[int, slice]) -> Union[Datum, Dataset]
```

Gets an item from the dataset, either via an int or slice. In the case of an
int then a Datum instance is returned, and for a slice a Dataset instance is
returned.

**Arguments**:

- `item` - integer or slice for extraction.
  

**Returns**:

  A Datum or Dataset instance, for int and slice queries respectively.

<a id="dataset.Dataset.__rich_repr__"></a>

---

### \_\_rich\_repr\_\_

```python
def __rich_repr__() -> List[Datum]
```

Used by the rich package for representing and print the instance.

<a id="types"></a>
